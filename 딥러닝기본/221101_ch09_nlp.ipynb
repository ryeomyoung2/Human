{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## chapter 7장 시계열 분석\n",
        "- 통계 (중급)\n",
        "  + 참조 : https://otexts.com/fppkr/\n",
        "- 페이스북 시계열 예측 라이브러리\n",
        "- 딥러닝 : 일반적인 알고리즘 LSTM \n",
        "- LSTM\n",
        "  + 시계열 & 자연어 처리할 때 도움 줌\n",
        "  + ch10장에서 LSTM을 대체하는 다양한 알고리즘이 이미 나옴. "
      ],
      "metadata": {
        "id": "jW3uhgDxizGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chapter 8장 성능 최적화\n",
        "- 하이퍼파라미터 튜닝 (교재 p327)\n"
      ],
      "metadata": {
        "id": "q_WvfrWJki6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chapter 9장 \n",
        "- p363 \n",
        "- 어간추출 : 영어 동사원형 추출한다. \n",
        "- "
      ],
      "metadata": {
        "id": "4Fro43SxlMFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 자연어 처리 라이브러리\n",
        "- NLTK 라이브러리 (https://www.nltk.org/)\n",
        "  + 말뭉치\n",
        "  + 토큰 생성\n",
        "  + 형태소 분석\n",
        "  + 품사 태깅"
      ],
      "metadata": {
        "id": "GEqoskuYmrY6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiTuKXuEiyGR",
        "outputId": "9d996f93-1b1c-45e0-aca2-d9ba7a8fcb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt') #  문장을 단어로 쪼개기 위한 라이브러리\n",
        "string1 = \"my factorite subject is math\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(string1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3pfp7Yvn0K1",
        "outputId": "7730574f-9920-4862-e6a6-24d74c6b88b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'factorite', 'subject', 'is', 'math']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WSL2 설치 (Ubuntu)\n",
        "- 이번주 금요일 설치\n",
        "- p373 설치 시도"
      ],
      "metadata": {
        "id": "pC6jGYX3oE92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install konlpy"
      ],
      "metadata": {
        "id": "e-xbowkuoSsE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gensim \n",
        "- 워드투벡터 라이브러리\n",
        "- 단어를 숫자로 바꾸는 것\n",
        "  + CountVectorizer, Tfidf (희소행렬 문제점)\n"
      ],
      "metadata": {
        "id": "sHgGoVjYokkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결측치 확인"
      ],
      "metadata": {
        "id": "FPOtC7DgpFQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB2BIF7zpICF",
        "outputId": "a9d1ee4a-0e73-4cbd-85f7-be7e7e95b157"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/산대특/ch09/data/class2.csv'\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(df.shape)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "f3nO9eLMpUV_",
        "outputId": "825b7326-c761-42c4-bf43-0a340284ca4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
              "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6104512-31eb-48fd-bcf1-a3780121240f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tissue</th>\n",
              "      <th>class</th>\n",
              "      <th>class2</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>mdb000</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>N</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mdb001</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>N</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>mdb002</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mdb003</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mdb004</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>I</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>B</td>\n",
              "      <td>544.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6104512-31eb-48fd-bcf1-a3780121240f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6104512-31eb-48fd-bcf1-a3780121240f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6104512-31eb-48fd-bcf1-a3780121240f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결측치 처리"
      ],
      "metadata": {
        "id": "dccFk3-mpnpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(how='all') # 모든 행이 NaN 일 때만 삭제\n",
        "print(df.shape)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "oc_GUvImpojd",
        "outputId": "2b06a2e2-65ad-416e-c7a7-e770f6374a94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
              "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-063bc088-6443-4169-8b31-59665d1e4b24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tissue</th>\n",
              "      <th>class</th>\n",
              "      <th>class2</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>mdb000</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>N</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mdb001</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>N</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>mdb002</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mdb003</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mdb004</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>I</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>B</td>\n",
              "      <td>544.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-063bc088-6443-4169-8b31-59665d1e4b24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-063bc088-6443-4169-8b31-59665d1e4b24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-063bc088-6443-4169-8b31-59665d1e4b24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰화\n",
        "- 주어진 텍스트를 단어/문자 단위로 자른다. \n",
        "- 영단어는 띄어쓰기가 어느정도 확실함"
      ],
      "metadata": {
        "id": "MBtP9i0BtYlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "from nltk import sent_tokenize\n",
        "text_sample = 'Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language. In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.'\n",
        "\n",
        "tokenized_sentences = sent_tokenize(text_sample)\n",
        "print(tokenized_sentences)\n",
        "print(len(tokenized_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp1kP-KWt7r6",
        "outputId": "c8869fa4-57ee-44f0-9083-70eac2daf6c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language.', 'In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 토큰화\n",
        "from nltk import word_tokenize \n",
        "sentence = \" This book is for deep learning learners\"\n",
        "words = word_tokenize(sentence)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "081lmKEkuT3l",
        "outputId": "a729ffc2-652b-4b82-826c-6c01a28dce94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'book', 'is', 'for', 'deep', 'learning', 'learners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아포스트로피(') 단어 토큰화\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
        "\n",
        "words = WordPunctTokenizer().tokenize(sentence)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-kmz2yEuvbH",
        "outputId": "a70db06b-6921-49c8-db2d-7edd294a7c85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it', '’', 's', 'nothing', 'that', 'you', 'don', '’', 't', 'already', 'know', 'except', 'most', 'people', 'aren', '’', 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 케라스를 이용한 단어 토큰화"
      ],
      "metadata": {
        "id": "_vdyl0U8vQiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아포스트로피(') 단어 토큰화\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
        "\n",
        "words = text_to_word_sequence(sentence)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHXj4r8vvTYF",
        "outputId": "4dee2b45-d240-42bd-8f5a-3da8acd4c80f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it’s', 'nothing', 'that', 'you', 'don’t', 'already', 'know', 'except', 'most', 'people', 'aren’t', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한글 토큰화"
      ],
      "metadata": {
        "id": "aPbTh54duumG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-39AHO7vtSH",
        "outputId": "7e8a0822-a7b0-4cea-9425-9182cc0b47f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv \n",
        "from konlpy.tag import Okt \n",
        "from gensim.models import word2vec \n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/산대특/ch09/data/'\n",
        "f = open(DATA_PATH + r'ratings_train.txt', 'r', encoding='utf-8')\n",
        "rdr = csv.reader(f, delimiter='\\t')\n",
        "rdw = list(rdr) \n",
        "f.close()"
      ],
      "metadata": {
        "id": "W94SiOSfv7Pm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdw[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udiIInSwwT02",
        "outputId": "81eb6ab0-2ee0-43a7-9456-f02f20ad3739"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['id', 'document', 'label'],\n",
              " ['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'],\n",
              " ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter = Okt()\n",
        "\n",
        "result = []\n",
        "for line in rdw:\n",
        "    malist = twitter.pos( line[1], norm=True, stem=True)\n",
        "    r = []\n",
        "    for word in malist:\n",
        "        if not word[1] in [\"Josa\",\"Eomi\",\"Punctuation\"]:\n",
        "            r.append(word[0])\n",
        "    rl = (\" \".join(r)).strip()\n",
        "    result.append(rl)\n",
        "    print(rl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lm_9aNfZxOA-",
        "outputId": "13456ef4-c225-4b03-9faa-a55ff97a64d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document\n",
            "아 더빙 진짜 짜증나다 목소리\n",
            "흠 포스터 보고 초딩 영화 줄 오버 연기 가볍다 않다\n",
            "너 무재 밓었 다그 래서 보다 추천 다\n",
            "교도소 이야기 구먼 솔직하다 재미 없다 평점 조정\n",
            "사이 몬페 그 의 익살스럽다 연기 돋보이다 영화 스파이더맨 늙다 보이다 하다 커스틴 던스트 너무나도 이쁘다 보이다\n",
            "막 걸음 마 떼다 3 세 초등학교 1 학년 생인 8 살다 영화 ㅋㅋㅋ 별 반개 아깝다 움\n",
            "원작 긴장감 제대로 살리다 하다\n",
            "별 반개 아깝다 욕 나오다 이응경 길용우 연 기 생활 몇 년 정말 발 해도 그것 낫다 납치 감금 반복 반복 이 드라마 가족 없다 연기 못 하다 사람 모 엿 네\n",
            "액션 없다 재미 있다 몇 안되다 영화\n",
            "왜 이렇게 평점 낮다 꽤 볼 한 데 헐리우드 식 화려하다 너무 길들이다 있다\n",
            "걍 인피니트 짱 진짜 짱 ♥\n",
            "볼때 눈물나다 죽다 90년 대의 향수 자극 허진호 감성 절제 멜로 달인\n",
            "울면 손 들 횡단보도 건너다 때 뛰다 치다 올 뻔 이범수 연기 드럽다 못 하다\n",
            "담백하다 깔끔하다 좋다 신 문 기 사 로만 보다 보다 자꾸 잊어버리다 그 들 사람 이다 것\n",
            "취향 존중 한 다지 진짜 내생 극장 보다 영화 중 가장 노잼 노 감동 임 스토리 어거지 감동 어거지\n",
            "ㄱ 냥 매번 긴장 되다 재밌다 ㅠㅠ\n",
            "차다 사람 들 웃기다 바스코 이기 락스 코 끄다 바비 이기 아이돌 깔다 그냥 끄다 안달 것 보이다\n",
            "굿바이 레닌 표절 것 이해 하다 왜 뒤 갈수록 재미 없어지다\n",
            "이 것 정말 깨알 캐스팅 질퍽 하 않다 산뜻하다 내 용구성 자다 버무러진 깨알 일드 ♥\n",
            "약탈 자 위 변명 이르다 저 놈 들 착하다 놈 들 절대 아니다 걸\n",
            "나름 심오하다 뜻 있다 듯 그냥 학생 선생 놀다 영화 절대 아니다\n",
            "보다 웃다 않다 건 불가능하다\n",
            "재미없다 지루하다 같다 음식 영화 도 바베트 만찬 넘다 차이나다 바베트 만찬 이야기 있다 음식 보다 재미 있다 이 것 볼 없다 음식 별로 안 나오다 핀란드 풍경 구 경 할랫 늘다 그것 별로 안 나오다 ㅡㅡ\n",
            "절대 평범하다 영화 아니다 수작 는걸 말씀드리다\n",
            "주제 좋다 중반 지루하다\n",
            "다 짤랐을꺼 그래서 납득 하다 수 없다 그렇다 꼭 그렇다 끄다\n",
            "kl 2 g 고추 털다 버리다 하다\n",
            "카밀라 벨 발연기\n",
            "재밌다 뎅\n",
            "센스 있다 연출 력 탁월하다 캐스팅 90년 대의 향수 그래서 9 점\n",
            "엄포스 위력 다시 한번 깨닫다 해주다 적 남 꽃 검사 님 연기 정말 좋다 완전 명품 드라마\n",
            "졸 쓰레기 진부하다 도안 돼다 ㅋㅋ 아 시간 아깝다\n",
            "재밌다 별 점 왜 이리 낮다\n",
            "1% 기대하다 내 죄인 이다 죄인 이다\n",
            "아직도 이 드라마 내 인생 최고\n",
            "패션 대한 열정 안나 윈 투어\n",
            "키이라 나이틀리 연기 하다 하다 대체 정신장애 이다 틱장애 이다\n",
            "허허 원작 정신 나가다 유령 재미있다\n",
            "포스터 있다 보이다 관객 114 명\n",
            "이 영화 왜 이렇게 저 평가 받다 모르다\n",
            "단순하다 은은하다 매력 영화\n",
            "다 알바생 내용 없다 무섭다 없다 웃기다 하나 없다 완전 별 싱겁다 영화 ㅇ ㅇ 내 ㅇ 시간 넘다 아깝다 움 완전 낚임\n",
            "오다 두다 서리 한 이 굶주리다\n",
            "정말 맘 들다 그래서 또 보다 또 보다 방법 없다 ㅜㅡ\n",
            "윤제문 멋지다 배우 발견 하다 돼다 소소하다 일 탈 잔잔하다 미소 먹음 하다 음악 조금 아쉽다 ㅠㅠ 8 점 주다 싶다 평점 올리다 싶다 10 점 주다\n",
            "평점 속지 말다 시간 낭비 돈 낭비 임\n",
            "리얼리티 뛰어나다 크다 공감 안 간다 이민기 캐릭터 정신의학 상 분노조절 장애 초기 증상 이다 툭하면 사람 패 욕 물건 파손 조금 오 바 이다 극 초반 신선하다 가면 갈수록 이민기 정신 상태 공감 불가\n",
            "마이너스 왜 없다 ㅋ 뮤비 보고 영화 수준 딱 알 하다 ㅉㅉ 북한 이렇다 만들다 돈 대다\n",
            "난 우리 영화 사랑 하다\n",
            "데 너 리스 타르 가르다 나다 용의 주인 되다 싶다 누 근친상간 하다 다니다 소설 속 제일 멋지다 놈 자 이 메 니스 터 이다 드라마 속 드래곤 용 이 제일 멋지다 웃음 감독 님 토르 2 다크 월드 말 잡수다 기본 선방 하다\n",
            "영화 사람 영혼 어루만지다 줄 수도 있다 거치다 세 상사 잠시 잊다 동화 같다 영화 행복하다\n",
            "야 세르게이 작다 고추 맵다 맛 보여주다 포퐁 저그 콩 진호 간다\n",
            "이렇게 가슴 시리 보다 드라마 또 있다 감동 그 자체\n",
            "난또 저 꼬마 애가 무슨 원한 깊다 하다 OO 그냥 혼자 나대다 OO 걸 어쩌라고\n",
            "재미있다\n",
            "전 좋다\n",
            "최고\n",
            "너무 충격 적다 기분 완전하다 푹 꺼지다 하다 느낌 활 력 하나 없다 너무나도 무겁다 지독하다 차갑다 무자비하다 그저 일본인 들 상상력 정말 대단하다 같다 생각 들다\n",
            "심심하다 영화\n",
            "백봉기 언제 나오다\n",
            "보다 그대로 들어맞다 예측 카리스마 없다 악역\n",
            "불알 나오다 당황 아무튼 영화 중간 끝나다 느낌\n",
            "평범하다 속 녹다 평범하다 일상 조금 밋밋하다 흠\n",
            "보다 계속 보다 전개도 느리다 주인공 은희 한두 컷 나오다 소 극적 모습 짜증 ㅜㅜ 맨날 언제 끝나다 기 대만 있다 전개 좀 빨리 빨리 ㅜㅜ\n",
            "사랑 싶다 가슴속 온 감정 헤집다 영화 정말 최고\n",
            "많다 사람 들 이 다큐 보고 우리나라 슬프다 현대 사의 하다 단면 대해 깊이 생각 사죄 바로 잡기 위해 노력 하다 하다 말로 듣다 보도 연맹 그 민간인 학살 이정 일 줄 이 것 명백하다 살인 이다 살인자 들 다 어디 있다\n",
            "예전 작품 캐릭터 에피소드 재탕 삼 탕 사골 우려 먹듯 우리 내용 산 가다 시청률 아예 안 나오다 이제 70회 중반인데 120 부작\n",
            "김남길 백 점 짜다 연기력 초반 몰입도 불구 지루하다 손예진 ㅈㅈ\n",
            "재밌다 비슷하다 영화 안 보다 분 들 늘다 재미있다 듯\n",
            "노래실력 뽑다 맞다 박시환 mama 나가다 진짜 망신\n",
            "아 일본 영화 다 이렇다 유치하다\n",
            "이틀 다 보다 재밌다 근데 차 안 물건 넣다 조작 하다 하다 차 안이 열리다 집 안이 활짝 열리다 아무나 들어가다 문자 조작 하다 비번 안 걸리다 ㅋㅋㅋ 그렇다 건 억지스럽다 그래도 내용 자체 좋다\n",
            "졸작\n",
            "재밌다 달팽이 빨 더 재밌다\n",
            "어설프다 전개 어이없다 결말\n",
            "부패하다 로마노프 왕조 기리 뭣같 영화 온몸 항거 하다 러시아 민중 들 그저 폭도\n",
            "내용 전개 무난 펴다 자다 보다\n",
            "매우 실망\n",
            "한국영 화 흥행 코드 갈등 갈등 계 속 갈등 화해 감동 평점 10 점 남발 흥행 뻔하다 뭐\n",
            "아햏햏 아햏햏 아햏햏\n",
            "뭐 시작 3분 만에 나오다 리플릿 사진 보다 불안하다\n",
            "단연 최고 하다\n",
            "감독 럼 먹다 영화 만들다 관객 뭘 말 하다 모르다 엉망 진창 개 진창\n",
            "이 것 뭐 우뢰매\n",
            "정말 쓰레기 영화 이다\n",
            "진정 위대하다 영화 최고 임\n",
            "별루 이다\n",
            "내일 기대 되다\n",
            "근데 조미 막문위 좋아하다 가요\n",
            "ㅋㅋㅋ 진짜 골깜 ㅋㅋ 눈 부라리다 때 쓰러지다 ㅋㅋ\n",
            "성룡 영화 중 최악 듯 ㅋㅋ\n",
            "골 때리다 ㅋㅋㅋ 걸스데이 이혜리 자다 되다\n",
            "서기 이쁘다\n",
            "완전 재밌다 ㅋㅋㅋ 백 인공 주귀 움 ㅋㅋㅋ\n",
            "인상 적 영화 이다\n",
            "어내스트 셀레스틴 완전 강추 정말 재밌다\n",
            "재미있다 영화 이다\n",
            "클라라 볼라 화신 보다 아니다\n",
            "진짜 보다 너무 슬프다 영화\n",
            "설정 재밌다 새롭다 에피소드 내 메인 스토리 차차 나오다 재밌다\n",
            "신카이 마코토 작화 밉다 유 하나 카나 연기 잘 해주다 더 대박 이다\n",
            "재미없다 진심 1 이훨 캐스팅 두 못 한 듯\n",
            "잔잔하다 생각 볼 만 영화 같다 ㅋ\n",
            "감독 님 들다 고은님 쓰다 영화 안 보다\n",
            "무섭다 않다 스토리 ㅡㅡ\n",
            "영화 속 억지스럽다 노골 적 술 광고 좀 은은하다 센스 있다 하다 어떻다\n",
            "킬링타임\n",
            "크리스마스 하다 떠오르다 영화\n",
            "재미있다 보다 매력 적 행복 요 ㅎㅎㅎ\n",
            "음악 완전하다 빠지다 볼 수 있다 영화 쫌 산만하다 하다\n",
            "태어나다 처음 영화 중간 나오다 불륜 로맨스\n",
            "왕 짜증 아주 전개 짬뽕 믹스 하다 음향 무섭다 하다 하아\n",
            "솔직하다 난 별루더 시간 낭비 느낌\n",
            "대박\n",
            "시청률 기준 되다 패널 가구 들 머 하다 명작 드라마 다 망치 ㅡㅡ 내 다 서운하다\n",
            "내용 이상하다\n",
            "몬스터 주식회사 3 D 재밌다 보다\n",
            "내용 전개 너무나 느리다\n",
            "소재 흥미 끌 이야기 전개 투 박하다 몰입 안되다\n",
            "절대 보다 쓰레기 영화\n",
            "중국인 특유 과장 허풍 있다 보이다 안간힘 쓸다 노력 가상하다 고증 현 실감 떨어지다 설정 거북 스럽다 도대체 그 들 왜 이렇게 스스로 과대 포장 하 것\n",
            "그냥 불법체류자 때리다 잡다 영화 좋다 무슨 우상화 만들다 미국 따뜻하다 설정 이 것 뭐임\n",
            "2년 의 삶속 주인공 생애 전부 드러나다 듯 하다\n",
            "별 점 10 점 가다\n",
            "별로\n",
            "보다 꽤 지난 후 남다 재미있다\n",
            "아니다 이 왜 9 점 대 이다\n",
            "10년 이 지나 다시 보다 되다 영화 다시 보다 그 순수하다 사랑 감동 ㅠㅠ 숀펜 연기 또한 甲\n",
            "올레 공짜 있다 보다 ㅋㅋ 헐다 스토리 문제 아니다 연기자 들 전혀 배역 어울리다 않다 그리고 상대 배우 들 다 따로 놓다 같다 이 것 연기자 들 문제 있다 보아 진심 완전 별로 임 라미란 아들 젤 볼 하다\n",
            "너무 욕심 많다 영화 어느 하다 쪽 제대로 보여주다\n",
            "아 빵점\n",
            "베댓 말 아주 잘쓰다\n",
            "아주 모자라다 않다\n",
            "영화 도둑 들 뫼비우스 하다 같다 나라 만들어지다 믿어지다\n",
            "온몸 찌릿 짜릿 나 용기 가다\n",
            "정말 재미있다 교훈 적 영 화이 네\n",
            "당시 상황 주제 주입 식이 아니다 긴장감 있다 재밌다 전하 작품\n",
            "케이블 그만 나오다 주다\n",
            "다르덴 이다 투 차이밍량 하나 안 섞이다 채 짬뽕 그릇 담기다\n",
            "여군 잼 없다 뭐 하다 건지다 ㅡㅡ 잼 없다 엠비씨 다 잼 없다 질린다 이제\n",
            "좋다\n",
            "한석규 김혜수 연기 돋보이다 영화 어디 모르다 많이 어설프다 영화\n",
            "솔직하다 에볼라 바이러스 떠들다 석 해 보다 되다 영화 작품 성 어떤 면 20 여 년전 영화 보기 믿다 힘들다 정도 정말 잘 만들다 보다 마지막 후반 부가 살짝 아쉽다 하지만 이 정도 수작 보다 시간 아깝다 않다 영화\n",
            "볼 만해\n",
            "재미있다 허풍 떨다 말다\n",
            "용가리 진짜 짱짱맨 ㅋ\n",
            "이 영화 이제 서다 보다 감히 내 인생 최고 영화 중 하나로 꼽 수 있다 작품 어떻다 살 야하다 나르다 위 고민 한번 더 하다 되다 시간 그리고 모건 프리 멀다 나이 들다 여전하다 섹시하다\n",
            "작가 별로 내 용이 진짜 별로 임 맨날 그냥 기대 재방송 하다 혹 시나 보다 답 없다 진짜\n",
            "명작 이렇다 명작 있다 싶다 보고 또 보다 여운 남다 영화\n",
            "아 진짜 조금 더 손 좀 보다 웬만하다 상업 영화 못 않다 퀄리티 쩔다 만들다 질 수 있다 아쉽다 그래도 충분하다 재미있다 개인 적 조금 더 잔인하다 더 자극 적 노출씬 화끈하다 하다 어떻다 하다 국산 영화 많이 아끼다 듯 보임\n",
            "그만 좀 끌 이제 끝내 지겹다 지겹다\n",
            "아\n",
            "역시 드니 의 연기 일품 나다 맥스 샘 죽이다 바랬다\n",
            "나름 괜찮다 작품 이다\n",
            "너무 좋다 영화\n",
            "정말 실망 스럽다\n",
            "배우 들 지네 들 안 뜨다 이런 영화 찍을껀데 왜 안 뜨다 진짜 모르다 면상 딱 보다 알다 왜 지네 자신 들 모르다\n",
            "어린이 좋아하다 내 어리다 적 동심 멀리 뜨다 낫다\n",
            "무술 인 왜 총을드\n",
            "10 점\n",
            "크리스토퍼 왈츠 타란티노 조합 ㅠㅠ\n",
            "한국 유명 한편 아니다 외국 상상 초월 유명하다 영화 이다\n",
            "오랜 만 재밌다 영화 보다\n",
            "종방 되어다 아쉽다 오늘 막 방도 잘 보다 방송 대본 꽤 완성 있다 느낌 받다 요즘 드라마 들 막장 지치다 수백향 정말 바른 드라마 이다 해 악역 들 그리다 심하다 어이없다 않다 MBC 화이팅\n",
            "평점 조절 위원회 나오다 웃음 김혜선 내일 오다 의 김 순정 순정 역할 제일 팜므파탈 로써 그 정도 잘 해내다 줄 정말 의외 이다 연기 20년 한 사람 요즘 사극 벌어지다 있다 그녀 대한 연 기 논란 왠지 코미디 한 장면 같다 웃음\n",
            "영화 끝 나가다 때 쯤 멍하다 다 보다 한마디 나오다 임 ㅈ 같다\n",
            "공유 존잘 ㅎㅎㅎ\n",
            "상쾌 발랄하다 영화 말 하다 껄끄런 성 소재 유쾌하다 해설 하다\n",
            "소파 죽 앉다 지키다 볼 이유 없다 작품\n",
            "로큰롤\n",
            "주된 타겟 어린이 일반 적 논리 통 하다 않다 건 알다 하지만 게임 흥미롭다 않다 요원 주인공 너무 무능력하다 별로 재미없다 CG 배경 거슬리다\n",
            "뮤지컬 영화 사운드 녹음 엉망 남다 춤 못 추다 내용 뻔하다 뻔 주인공 들 목소리 너무 안 어울리다 어제 CGV 뛰다 나가다 참다 진심 말리 싶다 영국 저 예산 DVD 용 영화 뮤지컬영화 아니다 맘마미아 1/10 도 안되다\n",
            "어리다 보다 꽤 좋아하다 로맨틱코미디\n",
            "게이물 줄 모르다 보다\n",
            "알바 끄다 저\n",
            "이 영화 머임 내 왜 받다 보다 그것 알고싶다 이 영화 배우 들 스텝 들 감독 꼭두각시 이다\n",
            "4 대다 2 최악\n",
            "정말 아름답다 영화 이다\n",
            "자극 적 것 익숙해지다 현대인 보다 눈 떼다 힘드다 연출 력\n",
            "뻑 뻑 자다 읽다 볼걸 나다 당하다\n",
            "정말 짜증 극치 보여주다 영화 굉장하다 언밸러스 느낌 뚱뚱하다 못 생기다 남자 애 발연기 시종일관 보다 고역 듯 간간히 흘러나오다 잔잔하다 클래식 풍 의 음악 듣기 싫다 짜증나다 정도 상당하다 싫다 영화\n",
            "감동 감동 ㅜㅜ 정말 최고 네\n",
            "별 점 주기도 아깝다 얼마나 내용 진부하다 욕 안 나오다 보고 재밌다 하다 사람 초딩 들 죄송하다 너무 화가 나서다 아무 것 볼 없다 보지 말다 그냥 티비 판 짜지다 한 거 같다\n",
            "나 왠만하다 짜증 알다\n",
            "돼지 피 먹다 닭목 따다 장면 우웩 역시 무당 아무나 하다 아니다\n",
            "버리다\n",
            "유치하다 지루하다 잠 오다\n",
            "3 류 풍 판타지 3 점 가져가다\n",
            "윤종신 복귀 좋다 이하늘 도대체 왜 뽑히다 알다 없다 참가자 실력 따다 전 심사 위원 인격 실력 쌓다 오다 어 하 어허 그만 좀 하다\n",
            "광장 작품 옛날 것 보고 싶다\n",
            "내 생 최고 영화\n",
            "어린시절 너무 무섭다 재미있다 보다 추억 판타지영화 절대 나쁘다 짓다 금물 지옥 가요\n",
            "기존 멜로영화 형식 탈피 하다 하다 감정 절제 지나치다 너무 담백하다 영화\n",
            "난 사랑비 서준 쏙 빠지다 버리다 1.2 3초 만에 쏙 ㅋㅋ 난 절대 잊다 않다 후회 도안 하다\n",
            "이영화 보 교훈 주네 나다 남다 인생 화려하다 살다 말 안 나오다\n",
            "나름 추억 젖다 들다 좋다 ㅋㅋ 아무 생각 없이 가볍다 보고오다 추천\n",
            "단순하다 싸이코 물 벗어나다\n",
            "이 14년 도에 만들어지다 가요 아니다 예전 만들다 다시 개봉 건가 ㅠ 너무 허다 접해 ㅠ\n",
            "넘다 사랑스럽다 영화 ㅠㅠ 1 보고 2 연 이 어 보다 넘다 귀엽다 ㅠㅠ ♥♥\n",
            "청춘 영화 줄 수 있다 감성 넘치다 나다 이 순간 지나가다 다시 돌아오다 않다 그 순간 무한 하다 젊음 줄 수 있다 그렇다 감성\n",
            "TV 용 건담 시리즈 중 아직 최고봉\n",
            "개콘 요즘 갈수록 코너 들 다 노잼 웃음 이안 다\n",
            "사다코 한 이 서린 우물 펀치 ㅜㅜ 감동\n",
            "후세 사랑 하다 되다 결정 적 계기 그 시간 표현 되다 않다 시 람 생명 빼앗다 하다 이유 등 시 노 출현 하다 연극 으 로 더 알다 하다 생각 다 또한 시 노 얼마나 본능 절제 히 면서 시 하다 노력 하다 더 보여주다 좋다 뻔하다\n",
            "새벽 시간 하다 일본 영화 들 전부 개 졸작 일 본 영화 원 다\n",
            "강수연 나가다 그리고 최정원 신음 신\n",
            "아 정말 김혜성 너무 예쁘다 이현진 웃다 거 정말 하\n",
            "가발 쓰다 싶다\n",
            "화려하다 여정 이인상 깊다 ㅋㅋ 재밌다 ㅋㅋ 배두나 연 기 정말 잘 하다 ㅋ\n",
            "10 대들다 위 성적 호기심 영화\n",
            "감동 적 영화\n",
            "이 것 말 필요 없다 그냥 닥치고 보다\n",
            "각기 다른 사람 들 재밌다 멋지다 사랑 영화\n",
            "역시 미국드라마 파워 정말 알다 없다 그 미묘하다 사로자다 버리다 최고\n",
            "너무 너무 훈훈하다\n",
            "이 거 응답 하라 은지원 원 스스로 욕 하다 않다 ㅋㅋㅋ\n",
            "아 너무 웃기 배꼽 빠지다 뻔하다 내 컴 이 영화 있다\n",
            "구성 상당하다 부실하다 영화 역시 네이버 평점 믿다 없다\n",
            "장끌 로드 몰락 가져오다 오우삼 헐리우드 작품 중 가장 재미없다 졸작\n",
            "언 제적 영웅본색 연출 현실 성 제로 영화\n",
            "작다 하나 설레다 하다 학창시절 그때 그 느낌 다시 느끼다 보다 시간 이다 장면 하나 하나 대사 하나 하나 배경음악 하나 하나 버리다 없다 드라마\n",
            "진심 재미 없다 너무 평점 높다 화남\n",
            "더럽다 재미없다 어떻다 형태 도 오다 닿다 않다 허무하다 완벽하다 지루하다 영화 영양가 하나 없다 영화\n",
            "이승기 정말 연기 잘 하다 조연 들 연기 정말 잘 하다\n",
            "현실 꿈 꿈 현실\n",
            "오늘 현충일 특집 프로 보다 되어다 1963년 도의 매우 훌륭하다 작품 이다\n",
            "판 미로 동 급 trash of the trash\n",
            "제대 보 더 재밌다 ㅋㅋㅋ\n",
            "영화 보다 마음 휴가 다녀오다 느낌 소박하다 잔잔하다 지루하다 않다 그래서 다시 보다 영화 햇살 가득하다 비 이의 부엌 요리 인상 적\n",
            "코믹 한 건 좋다 짜임새 너무 허다 술 하\n",
            "1996년 그때 당시 우리 나라 이렇다 판타지 로맨스 없다 아직도 신현준 황 장군 연기 음 괜찮다 ㅎㅎ 한석규 전 성 시 대가 열리다 영화 이 때 한석규 뿅 가다 ♥\n",
            "일단 재생 하다 괴물 같다 서스펜스 귀신 같다 흡입 력\n",
            "하 진짜 댓글 보고 한번 쯤 볼 만 영화 같다 보다 기 차다 이 게 무슨 버킷리스트 죽다 직전 소원 들어주다 내 가보다 죽다 직전 막 살다 이다 같다 감동 없다 진짜 버킷리스트 란 영화 발톱 때 못 따라가다 쓰레기 영화 완존 실망\n",
            "이 시간 좀 밝다 긍정 적 드라마 보다 보다 보다 오버 하다 연기 들 거슬리다 연기 너 무표 요 홍혜정 역 이그 마도 후련 기도 시원하다 나머 지다 들다 답답하다 낼 월요일 해피 한 것 보고 싶다\n",
            "정치인 모순 정치범 모순\n",
            "어떻다 이렇다 상상 대단하다\n",
            "좀 어렵다 기도 하다 전쟁 대한 묘사 자다 모르다\n",
            "일본 10 주년 극장판 만들다 우리나라 10 주년 재개 봉하 이 것 좀 ㅄ 아니다\n",
            "한 대희 개그콘서트 보다 내 전화 끊음 개그콘서트 없애다 ㅡㅡ\n",
            "한 물 간 동 서양 두 배우 싸움판\n",
            "푸하하하 이 거 기대 안 하다 역시 ㅋ\n",
            "세계 최초 반공 애니매이션 역사 적 가치 있다\n",
            "감각 적 시각 바라보다 색다르다 느낌 사랑 문학 적\n",
            "엄마 무고 지다 딸 감옥살이 시키다 시키다 이해 안 돼다\n",
            "이영화 제발 책 보다 감독 미치다 겁니다 이따위 로 만들다 화가 날 정도 ㅡㅡ\n",
            "신나다 흑인음악 아이스 큐브 뿐 남다 없다\n",
            "드럽다 재미없다 시간 돈 내 시간 어쩔 건데\n",
            "그저 한마디 뿐 알리시아\n",
            "진짜 생생하다 느끼다 수 있다\n",
            "재밌다 평점 이상하다 싶다 정도 낮다\n",
            "옥소리 프로필 사진 1 점 남다 가다 ㅋㅋㅋ 완전 대박 진짜 아우 짜증나다\n",
            "드라마 너무 재밓당\n",
            "아 진짜 너무 좋다 ㅜㅜ 짱짱\n",
            "연기 굿\n",
            "이렇다 영화 다시다 안 나오다 그때 시절 잘 나타내다 같다 ㅎㅎ\n",
            "중간 정도 부터 보다 꽤 대단하다\n",
            "콩 끄다 제 맛 콩 끄다 제 맛\n",
            "이적 소설 재미없다\n",
            "액션영화 아니다 범죄 느와르 영화 허다 범죄 느와르 영화롭다 실패 작\n",
            "뭔가 알다 없다 매력 빠져들다 영화\n",
            "모녀 토막 살해 살인자 부 성 애 말 되다 감동 받다 사람 들 본인 들 피해자 되다 감동 받다 하다 진심 묻다\n",
            "재밌다 평점 왜 이렇게 구리지\n",
            "아 OOO 기 이 걸 보다 내 눈 아깝다 ㅡㅡ 진짜 아 놓다 진짜 OOO 기 명작 요\n",
            "필름 값 아깝다 재미 더럽다 없다 2 점 점 수준 것 들 매미 OO\n",
            "또 보고 싶다 어디서 보다\n",
            "영화 재미있다 드 ㅎㅎ\n",
            "남 주인공 연기력 안습 요 혀 짧다 소리 듣기 너무 힘들다 매니저 역활 분 남 주인공 하다 훨 좋다 생각 들다 정도 영화 자체 적당하다 볼 만 하다\n",
            "3 점 딱 액션 스릴러 액션 스릴 없다\n",
            "완전 스토리 엉망 이구 완전 비추다 ㅜ\n",
            "OOO 영화 뭘 전달 하다 모르다 오글거리다\n",
            "좋다 영화\n",
            "더빙 이상하다 할머니 월 익숙하다 ㄷㅔ\n",
            "이 2 편이 나오다\n",
            "모든 2% 씩 다 부족하다 아니다 50% 씩\n",
            "정말 말 그대로 쇼 하다 영화\n",
            "12년 전 보다 기억 나다 않다 진개 천카이거 감독 이름 세 자다 기억 하다 두다\n",
            "정은지 언니 연기 잘 하다 노래 잘 부르다 마지막 회 웃다 즐겁다 보다 트로트 연인 ♥\n",
            "이 웃기다\n",
            "망하다\n",
            "아이 시선 보다 전쟁 보다 내내 가슴 먹다 먹다 하다\n",
            "사람 들 재미없다 하다 레알 기대 안 하다 생각 볼 함 근데 여자애 복 순이 다투다 장면 그건 굳이 없다 돼다 생각 함 몰입도 겁나다 없애다 어색 해보다\n",
            "설정 연속극 같다 느낌 들다 하지만 배우 들 연기 뛰어나다\n",
            "여 주인공 인터뷰 하다 때 지루하다 죽다 알다 ㅡㅡ 그냥 저 킬링타임 용 스릴러\n",
            "전 밉다 박스 오피스 1 위 ㅋㅋ 그냥 몰다 하다 건가 어떻다 이런 영화 1 위 하다 옛날 80~90년 대 우뢰매 수준 물폭탄 싸움 ㅋㅋ 손 비다 손 물폭탄 나가다 다르다 뭐\n",
            "감독 여자 보다 기량 많이 딸리다\n",
            "또 보고 또 울 었 다\n",
            "이렇다 영화 하나 개연 성 없다 허무하다 만들다 버리다 조디 포스터 이쁘다 모습 남 영화\n",
            "굳다 굳다\n",
            "스토리 말 안되다 개막 장 사랑 이야기 아니다 이 걸 보고 계시다 당신 시간 돈 아끼다 휴 그래도 보다 호구\n",
            "네 놈 살리다 두기 쌀 아깝다 세기 명대사\n",
            "평점 너무 높다 전혀 재미있다 않다 쓸데없이 말 많다 이렇다 류 영화 조연 들 뒷받침 중요하다 조연 들 내용 자체 전혀 없다 또한 여배우 별로 매력 없다 이틀 전 저스트 위드 잇다 애니스톤 보고 이 영화 보다 그 런가 실망하다\n",
            "맛깔 나 드라마\n",
            "시베리아 거기 가다 훈련 하다 때 나오다 ost 개 작살\n",
            "이 것 시종일관 질 질왜 제목 야경 꾼 이다 지금 10회 가 넘어가다 즉 2 달이 넘어가다 앞 누군가 얘기 하다 이 거 100 부 작다 그렇다 또 하다 순간 모든 걸 훅 진짜 지루함 지존\n",
            "나이 들 수록 이해 가다 영화\n",
            "ㅠㅠ 슬픔\n",
            "장면 개연 성도 없다 아역 연기 못 무슨 추노 나오다 민폐 언 년 외국 파다 초반 그렇다 싸하다 저급 영화\n",
            "이 영화 정말 별루 결말 이상하다\n",
            "딱하다 재미 없다 킁\n",
            "송강호 정말 연기 하다 위해 태어나다 그로 인하다 우리 즐거움 느끼다 역시 송강호 연기 파다\n",
            "일본 영화 수입 금지 시절 비디오 테이프 돌리다 보다 불후 명작 아 그리다\n",
            "살인 소재 하다 영화 이 재밌다 줄 살인 대한 감독 해석 정말 재치 있다 대다 배우 님 들다 10 여 년전 모습 새롭웠 ㅋ 정말 유쾌하다 재밌다\n",
            "누 밉다 라파스 신봉선 닮다 안 보다\n",
            "케이블 그만 좀 재탕하다\n",
            "멋지다 정말 멋지다 말 이외 하다 말 없다\n",
            "98년 에 어떻다 이런 영화 만들어지다 의문 당대 최고 영화 지금 보다 퀄 결코 떨어지다 않다\n",
            "지금 이 거 티비 돈 내다 보다 내 한심하다\n",
            "쓰레기 연예인 재기 장 그러나\n",
            "굿 좋다\n",
            "많다 감동 준 드라마\n",
            "발 로만 영화 지지다 주인공 넘어지다 뒤 사람 들 유유 히 걸다 있다 발 CG 발연기 발 시나리오 내용 정말 뭐 같다 ㅋㅋㅋ\n",
            "적당하다 하다 언제 끝나다\n",
            "잊다 수 없다 안개 끼다 워터 루 다리 마스코트\n",
            "곤 사토시 감독 2010년 안타깝다 돌아가다 가슴 먹다 먹다 하다 정말 천재 적 감독 암 갈다 ㅠㅠ 이제 서다 다시 보다 모든 작품 대작\n",
            "많다 생각 하다 돼다 예 뼈 지고 싶다 맘 있다 과 하다 독 이겠다\n",
            "아 츠무구 없어지다 별 5 개다\n",
            "어리다 땐 조폭 영화로 알다 나이 들다 이 인생 하다 뭉클하다 영화 세상 살아가다 갈수록 오다 닿다 많아지다 세상 비정하다 비정하다 지다 따뜻하다 친구\n",
            "영상 너무나도 멋지다\n",
            "비디오 있다 보다 1997년 도인줄모를정도로 잘 만들다 긴장감 있다\n",
            "처 ㅝ 주\n",
            "2009년 에 만들어지다 재밌다 영화 기다 좀 다듬다 소재 좋다 몰입 감다 기 대 이상 매끄럽다 못 부분 있다 연기 둘 다 잘 하다\n",
            "철 지난 조폭 코미디 뼈대 있다 가문 이야기 섞다 둘 다 지루하다 박정아 비롯 하다 배우 들 보기 민망하다 연기 펼치다 기억 남다 건 하나 없다\n",
            "군더더기 없이 자다 진행 되다 재미 없다 문제\n",
            "심심하다 보다 재밌다 탑 연기 못 하다 알다 배우 포스 나다 자다\n",
            "고 다미 괜찮다\n",
            "아 지대 짜증 아빠 봣는데 민망하다 죽다\n",
            "0 점 못 주다\n",
            "빠순이 영화 ㅋㅋㅋ 훈훈하다 긔 재밌쎠\n",
            "최악 애니메이션 지루하다 재미없다 스토리 진부하다\n",
            "좋다 의도 다르다 불쾌하다 표현 법\n",
            "줄리아 로버츠 귀엽다 연인 이 거 5년 전꺼다\n",
            "신선하다\n",
            "예술가 로써 하다 사람 인생 당시 시대 적 상황 질 느끼다 수 있다 명작\n",
            "관객수 너무 아쉽다 영화 베테 더 류승완 감독 역작 더 강하다 악역\n",
            "한창 핵 펭귄 남북 거짓 평화로 전 국민 속 때 만들어지다 영화\n",
            "지금 티비 하다 못 보다\n",
            "여자애 한 명 자다 못 하다 몇 명 죽다 ㅋㅋ 답 없다 ㅋ\n",
            "성룡 헐리웃 작 중 단연 최고 ㅋㅋㅋ\n",
            "안습\n",
            "감독 의도 전혀 알아차리다 못 하다\n",
            "하나님 가정 오다 만들다 진리 이 신분 이만 영화 눈 보지 마음 보다\n",
            "2 편도 나름 흥미진진 한 데 핀 헤드 죽다 좀 아쉽다 점 이 랄 끄다\n",
            "국산 코미디 영화 중 난 신라 달밤 제일 좋다 뭔가 푸근하다 따뜻하다\n",
            "최악 영 화보 다가 자다 첨 임 지루하다 둑 뻔\n",
            "탄탄하다 배우 들 되다 머 하다 건지다\n",
            "영화 점점 끝 달려가다 몰입도 더 높아지다 영화 이번 처음 요\n",
            "결국 감독 자신 하다 싶다 의견 지존파 핑계 삼다 하다 한 듯 지존파 살인 정당화 정부 탓 이다 사회 탓\n",
            "사실 여부 떠나다 알 오다 아더 너무 매칭 안 돼다 원탁 기사 중 실제 검술 최고 수 랜슬롯 알 있다 트리스탄 못 싸우다 검술 마치 중국 검술 흉내 내다 같다 그리고 란슬롯 실제 쌍 검다 너무 매칭 안대 하 틀다 ㅋ 기네 비어 역도 미스\n",
            "대한민국 영화 수준 평균 치르다 하락 시키다 충분하다 C 급 영상 물\n",
            "0 점 없다\n",
            "재밌다\n",
            "재미없다 기대 완전 하다 완전 못 하다 실망\n",
            "종착역 없다 인생 대유 트레비스 단지 흘러가다\n",
            "돈 시간 아깝다 영화\n",
            "네러티브 하나 없다 예쁘다 음악 동영상 취미 영화 만들다 것 이 것 끝나다 잘 하다 음악 올인 하다\n",
            "배우 들 연기 좋다 뭘 말 하다 건지다\n",
            "학위 위조 성범죄자 문 제자 들 모으다 영화 찍다 왜 그렇다 제작비 아끼다 구 패자부활전 하다\n",
            "솔직하다\n",
            "완전 재미있다 애 들 보기 알맞다\n",
            "잔인하다 하다 무섭다 ㅠ 탑 멋있다\n",
            "무섭다 않다 기분 나쁘다 쩝\n",
            "군더더기 없다 깔끔하다 그러나 강하다 메세지 전달 뜻밖 차다 좋다 영화\n",
            "이 영화 최고다 그냥 최고 그렇다 줄 알\n",
            "그랜드 부다페스트 호텔 시리즈 같다 캐스팅 아깝다\n",
            "빨리 감기 하다 보다 투자 비다 많이 들다 것 같다 영화사 망하다 ㅎ\n",
            "도대체 뭐 재밌다 건지다 모르다 무슨 아이언맨 시리즈 개그 뛰어넘다 하다 어디서 웃다 야하다 모르다 내용 뭐 뜬금 없다 히어로 놀이 또 뭐 왜 이렇게 평점 높다 모르다\n",
            "왜 극 끌다 중심 있다 캐릭터 있다 하다 알 되다 영화 살인마 대적 하다 그리고 사건 해결 하다 인물 없다 그리고 왜 마지막 다 탈출 하다 나서다 잡히다 죽이다 당하다 이해 하다 없다 대체 조달환 정유미 왜 나오다\n",
            "진 짜다 리얼 개 쓰레기 영화 다 보고 나다 정말 찝찝하다 영화 절대 보다\n",
            "비록 로봇 점차 인간 감정 가지 자신 대해 고민 하다 결국 인간 되어다 죽다 앤드류 모습 내 보다 영화 중 최고 감동 선사 영화\n",
            "영구 땡 칠이 시리즈 레전드 영화\n",
            "초딩 때 친척 형 비디오 빌리다 서다 보다 기억 나다 너무 재미 없다 근데 나중 우연히 다시 보다 재밌다 그 땐 왜 그렇게 재미 없다 98년 이면 내 초등학교 2 학년 때 사촌형 당시 나름 최신 비디오 빌리다 오다 같다\n",
            "지루하다 고요하다 서글프다 시 선속 머물다 깊다 성찰 사색\n",
            "영화 진짜 보고 펑펑 울다 너무 슬프다 같다 ㅜㅜㅜ\n",
            "누가 더 혀 짧다 내기 하다 박빙 이다 같다\n",
            "애 둘 딸리다 심은하 그 눈부시다 미모 아름답다 영상 메인 주제가\n",
            "3 기 나오다 아직 안 풀리다 이야기 들 많다 극장판 정말 시간 가다 모르다 보다 역시 싸다 패\n",
            "개 노잼 뭔가 스토리 부족하다 다 이상하다 진짜\n",
            "답 없다 뭐 하다 건지다\n",
            "절망 슬픔 속 자신 챙기다 삶 잔인함 거부 비참하다 대하\n",
            "페이스 허다 같다 ㅋㅋㅋ\n",
            "시간 흐르다 퇴색 되다 않다 맛 있다 영화\n",
            "진짜 어마어마하다 여운 주다 멜로 영화 ㅎ\n",
            "소 피 마르 소 말 같다 않다 불륜 내용 다 망치다 물론 실제 역사 그렇다 똥 같다 이야기 전혀 없다 주인공 죽 때 공주 10 살다 한마디 만약 미국인 맞서다 싸우다 아메리칸 원주민 자유 투쟁 기다 절대 아카데미상 못 받다\n",
            "훈훈하다 따뜻하다 부정 느끼다\n",
            "잼\n",
            "전 정말 재미있다 보다\n",
            "어딘가 일어나고 일 일 것 같다 느낌 강하다 우베 볼 이렇다 영화 만들다 이유 누군가 실제 따르다 하다 하다 바라다 같다 정장 월 있다 애 들 보다 웃다\n",
            "림프비즈킷 OST 만 10 점 개봉 당시 극장 보다 영화 내내 오우삼 쥑 싶다 ㅋㅋ\n",
            "견자단 대박 엽문 시리즈 계속 되다\n",
            "정말 오월 멜로 정말로 보고 보고 또 보다 계속 보다 영화 순위 1 순위 하 늦다 밤 그렇다 야릇하다 느낌 들다\n",
            "흥미롭다 보다 여배우 들 이쁘다 반하다\n",
            "스토리 액션 그래픽 머 하나 건지다 없다 망작 그냥 게임 즐기다\n",
            "그냥 레전드 레전드\n",
            "평론가 명치 겁나다 때리다 싶다 정말 이 영화 재미없다 생각 하다 재미 있다 내 인생 도움 가장 크다 영화 이다 본인 깨달 싶다 꼭 보다 인생 바꾸다 겁니다\n",
            "키 아누 리브 스 최고 액션 영화\n",
            "소재 아름답다 영화 다소 아쉽다 부분 들 있다 이유 이 영화 영화 극적 로맨스 좀 더 사실 적 하다 남자 마음 시선 말 싶다 때문 아니다\n",
            "영화평론가 아니다 좋다 한번 보고 마는 영화 아니다 울리다 영화\n",
            "역시 효느 역시 재밌다 ㅋㅋㅋ 재탕 중\n",
            "4 대강\n",
            "간첩 색휘 들 애쓰다 밥 먹다 다니다\n",
            "좀 검증 되다 애 들 좀 출현 시키다 이탈리아 특집 장난 하다\n",
            "아 정말 짜증나다 절때 보다 껄욕 나오다\n",
            "슬프다 ㅠㅠ\n",
            "최악 환경 속 이렇다 만화 만들다 사람 들 경의 보내다\n",
            "What is this movie for\n",
            "여운 엄청 길다 남다 영화 이이경 사랑 하다 영화\n",
            "이딴 게 한국 영화\n",
            "짜다 이 게뭐 뭔\n",
            "굿 10 자 이상 가나다라\n",
            "짱 ㅎ 혼자 자식 키우다 살아오다 엄마 그 의아 들 힘들다 살아오다 서로 예민하다 날카로워지다 때 있다 결국 가족 ㅎ 아빠 사람 생각 최악 아니다 여자 확실하다 요구 하다 도와주다 그 말 왠지 짠하다 닿다 ㅎ 나 혼자 괜히 끙끙 거리 말 자 ㅡ 이런 단 순 한 생각 다\n",
            "CG 도 별로 전개도 별로 연기 별로 한마디 재미없다\n",
            "번 지수 잃다 갈팡질팡\n",
            "Yesterday when i was young\n",
            "너무 사랑스럽다 감동 적 영화 정말 좋다\n",
            "최고 영화\n",
            "13년 전 영활 다시 보다 공효진 코 평수 줄 콧대 높이다 완전 못 생기다 ㅎㅎ 호 권상우 화산고 때 왼쪽 팔자 심하다 지금 사라지다 더 잘생기다 장혁 멋지다 늙다 ㅋㅋㅋ 다시 보다 웃기다\n",
            "말랑말랑\n",
            "공부 열심히 하다 공부 안 하다 저런 OO 인생 사다\n",
            "그냥 최고다\n",
            "전쟁 이후 아픔 자다 그린 영화 마지막 장면 압 권 유대인 줄 알 더럽다 여기 도움 필요하다 동행 하다 토마스 더럽다 유태인 말 한 장면 그러나 유대인 인척 사실 유대인 가족사진 보다 미묘하다 감정 들 사슴 인형 밟다 며 대변 하다 므 찌다 영화\n",
            "오랜 만 동화 다운 동화 보다 기분\n",
            "감사하다 정말로 감사하다\n",
            "걍 두다 변태\n",
            "샤넬 인생 성공 이 아니다 샤넬 그 남자 들\n",
            "영화 내용 없다\n",
            "십 수년 세월 찰나 순간 찰나 순간 영원하다 기억 남기다 시간 상대성 이론 관 하다\n",
            "니노 이중인격 연기 두근거리다 ♥\n",
            "보다 울컥 핫 영화 재미 있다 무엇 감동 적임\n",
            "열정 돌진 싶다 만들다 영화\n",
            "연기력 유혹 하다 못 하다\n",
            "난감하다 재미 없다 세상 깜짝 놀라다 하다 센세이션 없다\n",
            "아무리 노력 하다 차이나타운 대놓고 베 끼다 것 용서 안 되다\n",
            "신화 화이팅 에릭 화이팅 모두 힘내다\n",
            "엔딩 넘다 슬프다\n",
            "영화관 가다 보다 더 좋다 어린시절 돌아가다 느낌 들다 만 감\n",
            "정말 최고 이다 ㅠㅠ 이민정 씨 신하균 씨 연기 너무 좋다\n",
            "몇 안되다 재밌다 보다 영화\n",
            "교양 시간 보고 좀 충격 먹다 영화 마지막 너무 슬프다 빨갱이 소리 지르다 몬초 갑자기 다른 단어 말 한 건 선생님 대한 그리움 미안하다 슬프다 몬초 마지막 좀 울먹이다 같다 하다\n",
            "잘 보다\n",
            "안 무섭다 귀신 애기 그렇다 그냥 깜놀 하다 하다 뿐\n",
            "뭐 하다 쥐 모든 것 다 어설프다\n",
            "배우 들 따뜻하다 연기 일상 힘겹다 움 그리다 현 실감 다 좋다\n",
            "남자배우 들 정말 미스캐스팅 연기력 안습 조은숙 김유미 연 기 땜 참고 보다\n",
            "1 차 세계대전 中 피고 진 청춘 들 무기 기술 력 20 t 세기 전쟁 일으키다 정치인 들 전쟁 지휘 하다 고위 장교 들 생각 19 세기\n",
            "책 분명하다 다른 시선 괜찮다\n",
            "내 이 거 왜 보다 싶다 한예슬 김태희 나오다 보다 듯 적월 개 쌤 ㅋㅋ\n",
            "솔직하다 6 점때 뭐 약간 더럽다 장면 빼다 7.5 정도\n",
            "오다 이연서 님 신인 답지 않다 연기력 자다 보다 다음 작품 또 뵙다 바라다\n",
            "반전 전부 아니다 영화 몇 번 보다 또 보고 싶다 영화\n",
            "피해자 있다 피의자 없다\n",
            "개다 멀다 주인공 지 혼자 복수 못 하다 주변 해주다 바라다 민폐 녀 아직도 끌리다 ㅡㅡ\n",
            "신선하다 소재 화끈하다 액션 스피디 전개\n",
            "이 영화 3 박자 디테 이다 정말 시가전 퀄리티 완벽하다 남자 사랑 대한 묘사 작 중 한석규 누군가 사랑 하다 마음 정말 디테 일이 대단하다 마지막 얘기 완 급 조절 완벽하다 이 영화 정말 멋지다\n",
            "탕웨이 찡 그녀 10 점 주기 충분하다\n",
            "감동 적 영화\n",
            "당시 대박 치다 영화 괜찮다\n",
            "억지스럽다 시나리오 지루하다 전개 1 편 보다 못 구성 등 2 편 안 나오다 나다 망작 배우 들 영 화보 눈 없다 안타깝다\n",
            "ㅋㅋㅋ 반도 안되다 영화\n",
            "이 영화 평점 높다 이유 모르다 ㅡ ㅡ\n",
            "평생 기억 하다 한 영화 정상 적 소재 아니다\n",
            "요즘 상황 보고 이 영화 생각나다\n",
            "많다 것 생각 하다 만들다 영화 이다 마지막 사람 들 짐승 보이 아수라 사람 같다 보이다\n",
            "진짜 재미 없다 영화 공통점 스포츠영화 군대 영화 자막 나오다 영화\n",
            "로버트 드니 의 광기 복수 연기 만끽 하다 있다 수작 서스펜스 스릴러물\n",
            "감동 감동 도가니탕\n",
            "세계 어디 서나 정치 경제 문화 사회 전반 걸치다 변화 절실 상황 변화 가져오다 방법 없다 함정 것 같다\n",
            "귀엽다 베다 똑똑하다 베다 예쁘다 귀엽다 친구 압삘럽 ㅎ\n",
            "당시 개봉 날 보고 울면 나오다 돈 아깝다 ㅋㅋ\n",
            "정말 최고 영화\n",
            "잔잔하다 숨막히다 영화 연출 대단하다 곳곳 숨다 복선 치밀하다 싶다 정도 섬세하다 감정 표현 거기 김영애 연기\n",
            "once upon a dream\n",
            "시나리오 연출 연기 어느 것 하나 갖추다 못 시간 넘다 아깝다 억지 싸구려 중국 신파 경극\n",
            "거부 하다 몸짓 저 하늘\n",
            "그만 빙빙 돌리다 밝혀지다 하다 안되다 보다 아직도 질질 끌다 짜증나다 안 보다 여기 또 사고 터지다 또 질질 끌 진짜 짜증나다 빨리 빨리 밝혀지다 밝혀지다 반전 있다 작가 님 이 드라마 사랑 재다 넘다 끌다 짜증나다\n",
            "졸다 보다 왜 이리 평정 높다 겨 내용 별거 없다 아오 감수성 영화 이 거\n",
            "기대하다 않다 영화 아름답다 움 밀려오다 꽤 괜찮다 영화\n",
            "진짜 한 번만 더 이런 영화 상영 하다 용서 하다 않다 지금 영화 보다 카톡 잇다 아 놓다 진짜\n",
            "살다 있다 생동감 잃다 박물관\n",
            "노땅 들 한심하다 추억 미화\n",
            "어리다 적 눈물 흘리다 웃다 기억 간신히 찾다 다시 보다\n",
            "인종차별 유괴 두 주제 불협화음\n",
            "고명환 연기 쩌 아니다 돈 없다 쓸다 후자 라면 보다 없다 영화\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a682c2a93152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmalist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmalist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 형태소 저장"
      ],
      "metadata": {
        "id": "sDiy6A6HxYu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NUKAuwHyeop",
        "outputId": "b0a045ea-3044-4c7f-a80d-0b8dcd7997b1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/산대특/ch09/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xNVpNpmylPv",
        "outputId": "06ff7c41-1c24-4f2d-92ea-803fc5709e3c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/산대특/ch09/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH5Mi7fJyuDY",
        "outputId": "d0b579fe-77ce-4afd-b9c1-91e99ec600c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class2.csv     covertype.csv.1\tNaverMovie.model  ratings_test.txt\n",
            "covertype.csv  covtype.csv\tNaverMovie.nlp\t  ratings_train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"NaverMovie.nlp\", 'w', encoding='utf-8') as fp:\n",
        "  fp.write(\"\\n\".join(result))"
      ],
      "metadata": {
        "id": "0g4ok8o8xaSQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec 모델 생성"
      ],
      "metadata": {
        "id": "VR84vuFXzTZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mData = word2vec.LineSentence(\"NaverMovie.nlp\")\n",
        "mModel = word2vec.Word2Vec(mData, size = 200, window=10, hs=1, min_count=2, sg=1)\n",
        "mModel.save(\"NaverMovie.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAW9UDkTzVjD",
        "outputId": "bf398e6a-ad33-49b5-cd84-c4aa3c2ea5e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불용어 제거"
      ],
      "metadata": {
        "id": "GJ47oJ6qzz9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sample_text = \"One of the first things that we ask ourselves is what are the pros and cons of any task we perform.\"\n",
        "text_tokens = word_tokenize(sample_text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "print(\"불용어 제거 미적용:\", text_tokens, '\\n')\n",
        "print(\"불용어 제거 적용:\",tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxzxMioz12g",
        "outputId": "68e390a8-fc2b-497c-8f9d-16e4c78acdf7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 미적용: ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'any', 'task', 'we', 'perform', '.'] \n",
            "\n",
            "불용어 제거 적용: ['One', 'first', 'things', 'ask', 'pros', 'cons', 'task', 'perform', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 어간 추출\n",
        "- 단어의 원형을 찾아준다. \n",
        "- NLTK : 포터(porter) & 랭커스터(lancaster) 알고리즘\n",
        "- 표제어 추출 : 어간 추출보다 성능이 더 좋음"
      ],
      "metadata": {
        "id": "HlheOibh0mR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# 포터 알고리즘\n",
        "print(stemmer.stem('obesses'),stemmer.stem('obssesed'))\n",
        "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
        "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
        "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
        "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRVrxon1hOA",
        "outputId": "dc41e8b1-7650-4a76-a69e-58b0d39d96f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obess obsses\n",
            "standard standard\n",
            "nation nation\n",
            "absent absent\n",
            "tribal tribalic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랭커스터 알고리즘\n",
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
        "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
        "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
        "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
        "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g20SwqGY1ofQ",
        "outputId": "ec16b549-6c1d-4dc8-ab59-9053fdb2cbe8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obsess obsess\n",
            "standard standard\n",
            "nat nat\n",
            "abs abs\n",
            "trib trib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 표제어 추출\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # 추가해주세요! \n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
        "print(lemma.lemmatize('standardizes'),lemma.lemmatize('standardization'))\n",
        "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
        "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
        "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKZBqABH1slP",
        "outputId": "514dc7fd-7d5d-4f21-c0fc-ecf04418414f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obsess obsess\n",
            "standardizes standardization\n",
            "national nation\n",
            "absentness absently\n",
            "tribalical tribalicalized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정규화\n",
        "- covtype.csv 파일 다운로드"
      ],
      "metadata": {
        "id": "e8gziNrX20ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9c3AXsP3Dde",
        "outputId": "c0fe5136-b848-4862-9a85-4f7d7b0dfe13"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class2.csv\t covertype.csv.2  NaverMovie.model  ratings_train.txt\n",
            "covertype.csv\t covertype.csv.3  NaverMovie.nlp\n",
            "covertype.csv.1  covtype.csv\t  ratings_test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/gilbutITbook/080263/releases/download/0.1/covtype.csv\n",
        "!wget https://datahub.io/machine-learning/covertype/r/covertype.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfbNEMCS2e_o",
        "outputId": "e7e32b83-78ac-4c4e-8ca6-2d3755be04de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 02:55:35--  https://datahub.io/machine-learning/covertype/r/covertype.csv\n",
            "Resolving datahub.io (datahub.io)... 188.114.97.3, 188.114.96.3, 2a06:98c1:3121::, ...\n",
            "Connecting to datahub.io (datahub.io)|188.114.97.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://pkgstore.datahub.io/machine-learning/covertype/covertype_csv/data/65fa25e575524edaf7bb187aebad6b40/covertype_csv.csv [following]\n",
            "--2022-11-01 02:55:36--  https://pkgstore.datahub.io/machine-learning/covertype/covertype_csv/data/65fa25e575524edaf7bb187aebad6b40/covertype_csv.csv\n",
            "Resolving pkgstore.datahub.io (pkgstore.datahub.io)... 188.114.96.0, 188.114.97.0, 2a06:98c1:3120::3, ...\n",
            "Connecting to pkgstore.datahub.io (pkgstore.datahub.io)|188.114.96.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103930879 (99M) [text/csv]\n",
            "Saving to: ‘covertype.csv.4’\n",
            "\n",
            "covertype.csv.4     100%[===================>]  99.12M  34.2MB/s    in 2.9s    \n",
            "\n",
            "2022-11-01 02:55:39 (34.2 MB/s) - ‘covertype.csv.4’ saved [103930879/103930879]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정규화 유무 모델링 결과 비교\n"
      ],
      "metadata": {
        "id": "LE40EOOa7Asp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsppgHz7Y0q",
        "outputId": "b78005fc-af10-4ae9-aed5-2d69808d5c9b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class2.csv\t covertype.csv.2  covtype.csv\t    ratings_test.txt\n",
            "covertype.csv\t covertype.csv.3  NaverMovie.model  ratings_train.txt\n",
            "covertype.csv.1  covertype.csv.4  NaverMovie.nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 교재 389\n",
        "df = pd.read_csv(\"covertype.csv\")\n",
        "x = df[df.columns[:54]]\n",
        "# y = df.Cover_Type (with covtype.csv)\n",
        "y = df['class']"
      ],
      "metadata": {
        "id": "CkmtoTv_7IFJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.Cover_Type.value_counts()"
      ],
      "metadata": {
        "id": "kyalu_YH-qzg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS2Xu10eEcV4",
        "outputId": "936b1bcc-9ee4-4188-c958-ca5088c7d02b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    283301\n",
              "1    211840\n",
              "3     35754\n",
              "7     20510\n",
              "6     17367\n",
              "5      9493\n",
              "4      2747\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQb_0B9G76Xl",
        "outputId": "ee30adcd-bf89-4557-b9bf-5ed249e0183b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((581012, 54), (581012,))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터셋 분리"
      ],
      "metadata": {
        "id": "V6PPb-d58Wt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, train_size = 0.7, random_state=90\n",
        ")\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8BgkHj8ELb",
        "outputId": "c22880ea-6f1b-47f1-b781-0f70ad689e2c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((406708, 54), (174304, 54), (406708,), (174304,))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yKoUDeD8y6F",
        "outputId": "612653ec-e8df-4169-9732-b4077e07fb82"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 만들기\n",
        "- class 0은 존재함, 그러나 ignored됨\n",
        "- 마지막 출력층은 8개로 입력해야 함"
      ],
      "metadata": {
        "id": "-cEtXtRP8ZeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, \n",
        "                          activation='relu', \n",
        "                          input_shape=(x_train.shape[1], )),\n",
        "    tf.keras.layers.Dense(64, activation='relu'), \n",
        "    tf.keras.layers.Dense(8, activation='softmax') \n",
        "])\n",
        "\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history1 = model.fit(\n",
        " x_train, y_train, epochs= 26, batch_size = 60, validation_data = (x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "-qRCMwnE8V6k",
        "outputId": "068cd5fc-b24a-479f-d757-8afcd91f072b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "6767/6779 [============================>.] - ETA: 0s - loss: 0.6367 - accuracy: 0.7281"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f4519fb34e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m history1 = model.fit(\n\u001b[0;32m---> 14\u001b[0;31m  x_train, y_train, epochs= 26, batch_size = 60, validation_data = (x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m       cache_key, cache_key_deletion_observer = function_context.make_cache_key(\n\u001b[0;32m-> 2677\u001b[0;31m           (args, kwargs))\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m       cache_key, cache_key_deletion_observer = function_context.make_cache_key(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[0;34m(args, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m    129\u001b[0m       include_tensor_ranks_only)\n\u001b[1;32m    130\u001b[0m   function_signature = trace_type.make_function_signature(\n\u001b[0;32m--> 131\u001b[0;31m       args, signature_context)\n\u001b[0m\u001b[1;32m    132\u001b[0m   return function_cache.FunctionCacheKey(\n\u001b[1;32m    133\u001b[0m       \u001b[0mfunction_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mmake_function_signature\u001b[0;34m(function_args, signature_context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mTraceType\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m    108\u001b[0m           type(obj), tuple(create_trace_type(c, context) for c in obj))\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m           type(obj), tuple(create_trace_type(c, context) for c in obj))\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m    108\u001b[0m           type(obj), tuple(create_trace_type(c, context) for c in obj))\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m           type(obj), tuple(create_trace_type(c, context) for c in obj))\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsTracingProtocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_tracing_type__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typing_extensions.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# assigned in __init__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             if ((not getattr(cls, '_is_protocol', False) or\n\u001b[0;32m--> 598\u001b[0;31m                  _is_callable_members_only(cls)) and\n\u001b[0m\u001b[1;32m    599\u001b[0m                     issubclass(instance.__class__, cls)):\n\u001b[1;32m    600\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typing_extensions.py\u001b[0m in \u001b[0;36m_is_callable_members_only\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_callable_members_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_protocol_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typing_extensions.py\u001b[0m in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__annotations__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             if (not attr.startswith('_abc_') and attr not in (\n\u001b[1;32m    566\u001b[0m                     \u001b[0;34m'__abstractmethods__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__annotations__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__weakref__'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 정규화"
      ],
      "metadata": {
        "id": "nqnJ-D5Y9yR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p390\n",
        "from sklearn import preprocessing \n",
        "df = pd.read_csv(\"covtype.csv\")\n",
        "x = df[df.columns[:55]]\n",
        "y = df.Cover_Type\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.7, random_state=90)\n",
        "\n",
        "# 중요 포인트 \n",
        "train_norm = x_train[x_train.columns[0:10]] # 훈련 10개의 컬럼 선택\n",
        "test_norm = x_test[x_test.columns[0:10]] # 테스트 10개의 컬럼 선택\n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(train_norm) \n",
        "x_train_norm = std_scale.transform(train_norm)\n",
        "\n",
        "traininig_norm_col = pd.DataFrame(x_train_norm, \n",
        "                                  index=train_norm.index, \n",
        "                                  columns = train_norm.columns)\n",
        "x_train.update(traininig_norm_col)\n",
        "print(x_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm9qhYO_911s",
        "outputId": "25909521-619e-46e4-d882-f1e4270dac64"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "152044   0.222366 -0.228639 -0.412503                          0.148486   \n",
            "363373   1.980490 -0.469989  0.255453                          3.018822   \n",
            "372733  -1.081933  0.271939  0.389044                         -0.867895   \n",
            "572846  -1.164122 -0.157128 -0.278912                         -1.267860   \n",
            "114145  -0.052787  0.861906  0.255453                         -0.279711   \n",
            "\n",
            "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "152044                        0.149095                         1.336119   \n",
            "363373                        4.443372                         0.168073   \n",
            "372733                       -0.160093                        -0.241801   \n",
            "572846                       -0.795646                        -0.461170   \n",
            "114145                       -0.125739                         1.811419   \n",
            "\n",
            "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "152044       1.002687        0.539776      -0.510339   \n",
            "363373       1.227001       -0.270132      -1.190275   \n",
            "372733       0.292357        1.349684       0.378807   \n",
            "572846       0.965301        0.641014      -0.431885   \n",
            "114145      -1.090917        1.299065       1.581770   \n",
            "\n",
            "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
            "152044                           -0.111226  ...            0            0   \n",
            "363373                           -0.703030  ...            0            0   \n",
            "372733                            0.038235  ...            0            0   \n",
            "572846                           -1.450334  ...            0            0   \n",
            "114145                           -0.328623  ...            0            0   \n",
            "\n",
            "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "152044            0            0            0            0            0   \n",
            "363373            0            0            0            0            0   \n",
            "372733            0            0            0            0            0   \n",
            "572846            0            0            0            0            0   \n",
            "114145            0            0            0            0            0   \n",
            "\n",
            "        Soil_Type39  Soil_Type40  Cover_Type  \n",
            "152044            0            0           2  \n",
            "363373            0            1           1  \n",
            "372733            0            0           3  \n",
            "572846            0            0           2  \n",
            "114145            0            0           2  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_norm = std_scale.transform(test_norm) # 테스트 데이터셋 정규화 \n",
        "testing_norm_col = pd.DataFrame(x_test_norm, \n",
        "                                index = test_norm.index, \n",
        "                                columns = test_norm.columns)\n",
        "\n",
        "x_test.update(testing_norm_col)\n",
        "print(x_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YVwQDCqA5fQ",
        "outputId": "1a40cf51-3160-4b72-ced9-1773e51d59f2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "204886   0.783394 -1.310245 -0.946867                          0.233185   \n",
            "116027  -0.903262 -1.006323 -0.679685                         -1.267860   \n",
            "328145  -0.270766 -1.095711 -0.278912                          0.379054   \n",
            "579670  -1.139108 -0.961628 -0.412503                          0.454342   \n",
            "41341    0.265247  0.736762 -1.347641                          2.708261   \n",
            "\n",
            "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "204886                       -1.465554                         0.093026   \n",
            "116027                       -0.795646                        -0.611906   \n",
            "328145                        0.200626                        -0.948657   \n",
            "579670                        0.389574                        -0.772905   \n",
            "41341                         2.072931                         2.321998   \n",
            "\n",
            "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "204886      -0.006729        0.084203       0.221899   \n",
            "116027       0.367128       -0.168893      -0.274977   \n",
            "328145       0.217585       -0.472609      -0.301128   \n",
            "579670       0.441900       -0.421989      -0.510339   \n",
            "41341       -0.006729        1.045968       0.718775   \n",
            "\n",
            "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
            "204886                            0.253368  ...            0            0   \n",
            "116027                            0.226194  ...            0            0   \n",
            "328145                           -0.330133  ...            0            0   \n",
            "579670                           -0.882685  ...            0            0   \n",
            "41341                             1.243735  ...            0            0   \n",
            "\n",
            "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "204886            0            0            0            0            0   \n",
            "116027            0            0            0            0            0   \n",
            "328145            0            0            0            0            0   \n",
            "579670            0            0            0            0            0   \n",
            "41341             0            0            0            0            0   \n",
            "\n",
            "        Soil_Type39  Soil_Type40  Cover_Type  \n",
            "204886            0            0           1  \n",
            "116027            0            0           2  \n",
            "328145            0            0           2  \n",
            "579670            0            0           3  \n",
            "41341             0            0           2  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        " tf.keras.layers.Dense(64, activation='relu',                  \n",
        " input_shape=(x_train.shape[1],)),\n",
        " tf.keras.layers.Dense(64, activation='relu'),\n",
        " tf.keras.layers.Dense(8, activation=  'softmax')\n",
        " ])\n",
        "\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "history2 = model.fit(\n",
        " x_train, y_train,\n",
        " epochs= 26, batch_size = 60,\n",
        " validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "IepHjWl9Bcdv",
        "outputId": "26cfd9c9-a309-4749-f111-38efd3af5a51"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "1100/6779 [===>..........................] - ETA: 16s - loss: 0.1553 - accuracy: 0.9558"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-b951556fd79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m  \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m  validation_data = (x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}